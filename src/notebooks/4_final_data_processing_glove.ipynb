{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Download Word2Vec\n",
    "model = api.load(\"glove-twitter-25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25763 entries, 0 to 25762\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   title            25763 non-null  object\n",
      " 1   tag              25763 non-null  object\n",
      " 2   s1_title_lower   25763 non-null  object\n",
      " 3   s2_clean_title   25763 non-null  object\n",
      " 4   s3_tokenized     25763 non-null  object\n",
      " 5   s4_no_stopwords  25763 non-null  object\n",
      " 6   s5_lemmatized    25763 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Adjust list of tokens to be equal to SUPPORTED_NUMBER_OF_TOKENS from global file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('../../output_data/2_tc_nltk_preprocessed.json')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>s1_title_lower</th>\n",
       "      <th>s2_clean_title</th>\n",
       "      <th>s3_tokenized</th>\n",
       "      <th>s4_no_stopwords</th>\n",
       "      <th>s5_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My personal ranking of Community's use of alte...</td>\n",
       "      <td>COMMUNITY</td>\n",
       "      <td>my personal ranking of community's use of alte...</td>\n",
       "      <td>my personal ranking of communitys use of alter...</td>\n",
       "      <td>[my, personal, ranking, of, communitys, use, o...</td>\n",
       "      <td>[personal, ranking, communitys, use, alternati...</td>\n",
       "      <td>[personal, ranking, community, use, alternativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It took 30 years for climate tech investments ...</td>\n",
       "      <td>ENVIRONMENT</td>\n",
       "      <td>it took 30 years for climate tech investments ...</td>\n",
       "      <td>it took 30 years for climate tech investments ...</td>\n",
       "      <td>[it, took, 30, years, for, climate, tech, inve...</td>\n",
       "      <td>[took, 30, years, climate, tech, investments, ...</td>\n",
       "      <td>[took, 30, year, climate, tech, investment, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rain when sitting in a car</td>\n",
       "      <td>RELAX</td>\n",
       "      <td>rain when sitting in a car</td>\n",
       "      <td>rain when sitting in a car</td>\n",
       "      <td>[rain, when, sitting, in, a, car]</td>\n",
       "      <td>[rain, sitting, car]</td>\n",
       "      <td>[rain, sitting, car]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is Cassis worth staying in?</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>is cassis worth staying in?</td>\n",
       "      <td>is cassis worth staying in</td>\n",
       "      <td>[is, cassis, worth, staying, in]</td>\n",
       "      <td>[cassis, worth, staying]</td>\n",
       "      <td>[cassis, worth, staying]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          tag  \\\n",
       "0  My personal ranking of Community's use of alte...    COMMUNITY   \n",
       "1  It took 30 years for climate tech investments ...  ENVIRONMENT   \n",
       "2                         Rain when sitting in a car        RELAX   \n",
       "3                        Is Cassis worth staying in?       TRAVEL   \n",
       "\n",
       "                                      s1_title_lower  \\\n",
       "0  my personal ranking of community's use of alte...   \n",
       "1  it took 30 years for climate tech investments ...   \n",
       "2                         rain when sitting in a car   \n",
       "3                        is cassis worth staying in?   \n",
       "\n",
       "                                      s2_clean_title  \\\n",
       "0  my personal ranking of communitys use of alter...   \n",
       "1  it took 30 years for climate tech investments ...   \n",
       "2                         rain when sitting in a car   \n",
       "3                         is cassis worth staying in   \n",
       "\n",
       "                                        s3_tokenized  \\\n",
       "0  [my, personal, ranking, of, communitys, use, o...   \n",
       "1  [it, took, 30, years, for, climate, tech, inve...   \n",
       "2                  [rain, when, sitting, in, a, car]   \n",
       "3                   [is, cassis, worth, staying, in]   \n",
       "\n",
       "                                     s4_no_stopwords  \\\n",
       "0  [personal, ranking, communitys, use, alternati...   \n",
       "1  [took, 30, years, climate, tech, investments, ...   \n",
       "2                               [rain, sitting, car]   \n",
       "3                           [cassis, worth, staying]   \n",
       "\n",
       "                                       s5_lemmatized  \n",
       "0  [personal, ranking, community, use, alternativ...  \n",
       "1  [took, 30, year, climate, tech, investment, pa...  \n",
       "2                               [rain, sitting, car]  \n",
       "3                           [cassis, worth, staying]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>s5_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMMUNITY</td>\n",
       "      <td>[personal, ranking, community, use, alternativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENVIRONMENT</td>\n",
       "      <td>[took, 30, year, climate, tech, investment, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RELAX</td>\n",
       "      <td>[rain, sitting, car]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>[cassis, worth, staying]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tag                                      s5_lemmatized\n",
       "0    COMMUNITY  [personal, ranking, community, use, alternativ...\n",
       "1  ENVIRONMENT  [took, 30, year, climate, tech, investment, pa...\n",
       "2        RELAX                               [rain, sitting, car]\n",
       "3       TRAVEL                           [cassis, worth, staying]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnecessary columns\n",
    "\n",
    "reduced_df = pd.DataFrame(df.drop(labels=['title', 's1_title_lower', 's2_clean_title', 's3_tokenized', 's4_no_stopwords'], axis='columns', inplace=False))\n",
    "reduced_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMMUNITY</td>\n",
       "      <td>[personal, ranking, community, use, alternativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENVIRONMENT</td>\n",
       "      <td>[took, 30, year, climate, tech, investment, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RELAX</td>\n",
       "      <td>[rain, sitting, car]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>[cassis, worth, staying]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tag                                         lemmatized\n",
       "0    COMMUNITY  [personal, ranking, community, use, alternativ...\n",
       "1  ENVIRONMENT  [took, 30, year, climate, tech, investment, pa...\n",
       "2        RELAX                               [rain, sitting, car]\n",
       "3       TRAVEL                           [cassis, worth, staying]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename column that contains lems\n",
    "\n",
    "reduced_df.rename(columns = {'s5_lemmatized':'lemmatized'}, inplace = True)\n",
    "reduced_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>lemmatized_no_numbers</th>\n",
       "      <th>vectorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMMUNITY</td>\n",
       "      <td>[personal, ranking, community, use, alternativ...</td>\n",
       "      <td>[personal, ranking, community, use, alternativ...</td>\n",
       "      <td>[[0.035234, 0.54248, -0.75981, -0.029171, 1.94...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENVIRONMENT</td>\n",
       "      <td>[took, 30, year, climate, tech, investment, pa...</td>\n",
       "      <td>[took, number, year, climate, tech, investment...</td>\n",
       "      <td>[[-0.39819, 0.92849, 1.1194, -0.13217, -0.2980...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RELAX</td>\n",
       "      <td>[rain, sitting, car]</td>\n",
       "      <td>[rain, sitting, car]</td>\n",
       "      <td>[[-0.94214, -0.24345, 0.20744, 0.21493, -1.066...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>[cassis, worth, staying]</td>\n",
       "      <td>[cassis, worth, staying]</td>\n",
       "      <td>[[-1.0744, -0.88249, 0.2764, 0.64755, -0.35475...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tag                                         lemmatized  \\\n",
       "0    COMMUNITY  [personal, ranking, community, use, alternativ...   \n",
       "1  ENVIRONMENT  [took, 30, year, climate, tech, investment, pa...   \n",
       "2        RELAX                               [rain, sitting, car]   \n",
       "3       TRAVEL                           [cassis, worth, staying]   \n",
       "\n",
       "                               lemmatized_no_numbers  \\\n",
       "0  [personal, ranking, community, use, alternativ...   \n",
       "1  [took, number, year, climate, tech, investment...   \n",
       "2                               [rain, sitting, car]   \n",
       "3                           [cassis, worth, staying]   \n",
       "\n",
       "                                          vectorized  \n",
       "0  [[0.035234, 0.54248, -0.75981, -0.029171, 1.94...  \n",
       "1  [[-0.39819, 0.92849, 1.1194, -0.13217, -0.2980...  \n",
       "2  [[-0.94214, -0.24345, 0.20744, 0.21493, -1.066...  \n",
       "3  [[-1.0744, -0.88249, 0.2764, 0.64755, -0.35475...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace every number by word 'number' and mixed letters with number to 'number'\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def replace_if_number(word):\n",
    "    if bool(re.match(r'^\\d+$', word)):\n",
    "        return 'number'\n",
    "    \n",
    "    if bool(re.search(r'\\d', word)): # Mixed such as 33m\n",
    "        return 'number' # TODO handle it better\n",
    "\n",
    "    return word\n",
    "\n",
    "reduced_df['lemmatized_no_numbers'] = reduced_df['lemmatized'].apply(lambda lem_list: [replace_if_number(lem) for lem in lem_list])\n",
    "\n",
    "# Set unknown words for word2vec to be 'unknown' and apply model\n",
    "\n",
    "def apply_word2vec_model(word):\n",
    "    # Check if the word exists in the model's vocabulary\n",
    "    if word in model:\n",
    "        return model[word]\n",
    "    \n",
    "    return model['unknown']\n",
    "\n",
    "reduced_df['vectorized'] = reduced_df['lemmatized_no_numbers'].apply(lambda lem_list: [apply_word2vec_model(lem) for lem in lem_list])\n",
    "\n",
    "reduced_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25763\n",
      "6\n",
      "25\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25763 entries, 0 to 25762\n",
      "Columns: 1100 entries, input_0 to input_1099\n",
      "dtypes: float64(1100)\n",
      "memory usage: 216.2 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_0</th>\n",
       "      <th>input_1</th>\n",
       "      <th>input_2</th>\n",
       "      <th>input_3</th>\n",
       "      <th>input_4</th>\n",
       "      <th>input_5</th>\n",
       "      <th>input_6</th>\n",
       "      <th>input_7</th>\n",
       "      <th>input_8</th>\n",
       "      <th>input_9</th>\n",
       "      <th>...</th>\n",
       "      <th>input_1090</th>\n",
       "      <th>input_1091</th>\n",
       "      <th>input_1092</th>\n",
       "      <th>input_1093</th>\n",
       "      <th>input_1094</th>\n",
       "      <th>input_1095</th>\n",
       "      <th>input_1096</th>\n",
       "      <th>input_1097</th>\n",
       "      <th>input_1098</th>\n",
       "      <th>input_1099</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035234</td>\n",
       "      <td>0.54248</td>\n",
       "      <td>-0.75981</td>\n",
       "      <td>-0.029171</td>\n",
       "      <td>1.94140</td>\n",
       "      <td>-0.17883</td>\n",
       "      <td>0.25397</td>\n",
       "      <td>0.49265</td>\n",
       "      <td>-0.00256</td>\n",
       "      <td>-0.43786</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.398190</td>\n",
       "      <td>0.92849</td>\n",
       "      <td>1.11940</td>\n",
       "      <td>-0.132170</td>\n",
       "      <td>-0.29808</td>\n",
       "      <td>-0.52848</td>\n",
       "      <td>1.06140</td>\n",
       "      <td>-0.70803</td>\n",
       "      <td>-0.48539</td>\n",
       "      <td>0.13713</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.942140</td>\n",
       "      <td>-0.24345</td>\n",
       "      <td>0.20744</td>\n",
       "      <td>0.214930</td>\n",
       "      <td>-1.06640</td>\n",
       "      <td>1.19490</td>\n",
       "      <td>1.52340</td>\n",
       "      <td>-0.16527</td>\n",
       "      <td>0.35522</td>\n",
       "      <td>0.43450</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.074400</td>\n",
       "      <td>-0.88249</td>\n",
       "      <td>0.27640</td>\n",
       "      <td>0.647550</td>\n",
       "      <td>-0.35475</td>\n",
       "      <td>0.25591</td>\n",
       "      <td>-0.70326</td>\n",
       "      <td>-1.00450</td>\n",
       "      <td>1.19360</td>\n",
       "      <td>-1.02990</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.177000</td>\n",
       "      <td>0.43200</td>\n",
       "      <td>0.21391</td>\n",
       "      <td>-0.295150</td>\n",
       "      <td>0.47344</td>\n",
       "      <td>-0.38013</td>\n",
       "      <td>1.60180</td>\n",
       "      <td>0.56238</td>\n",
       "      <td>0.40478</td>\n",
       "      <td>-0.57094</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_0  input_1  input_2   input_3  input_4  input_5  input_6  input_7  \\\n",
       "0  0.035234  0.54248 -0.75981 -0.029171  1.94140 -0.17883  0.25397  0.49265   \n",
       "1 -0.398190  0.92849  1.11940 -0.132170 -0.29808 -0.52848  1.06140 -0.70803   \n",
       "2 -0.942140 -0.24345  0.20744  0.214930 -1.06640  1.19490  1.52340 -0.16527   \n",
       "3 -1.074400 -0.88249  0.27640  0.647550 -0.35475  0.25591 -0.70326 -1.00450   \n",
       "4 -0.177000  0.43200  0.21391 -0.295150  0.47344 -0.38013  1.60180  0.56238   \n",
       "\n",
       "   input_8  input_9  ...  input_1090  input_1091  input_1092  input_1093  \\\n",
       "0 -0.00256 -0.43786  ...         NaN         NaN         NaN         NaN   \n",
       "1 -0.48539  0.13713  ...         NaN         NaN         NaN         NaN   \n",
       "2  0.35522  0.43450  ...         NaN         NaN         NaN         NaN   \n",
       "3  1.19360 -1.02990  ...         NaN         NaN         NaN         NaN   \n",
       "4  0.40478 -0.57094  ...         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   input_1094  input_1095  input_1096  input_1097  input_1098  input_1099  \n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 1100 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create single column per each number\n",
    "\n",
    "\n",
    "vectorized_token_list = reduced_df['vectorized']\n",
    "print(len(vectorized_token_list))\n",
    "print(len(vectorized_token_list[0]))\n",
    "print(len(vectorized_token_list[0][0]))\n",
    "\n",
    "rows = []\n",
    "for vectorized_token in vectorized_token_list:\n",
    "    single_row = {}\n",
    "    itx = 0\n",
    "    for vector in vectorized_token:\n",
    "        for number in vector:\n",
    "            single_row[f'input_{itx}'] = number\n",
    "            itx += 1\n",
    "        \n",
    "    rows.append(single_row)\n",
    "\n",
    "final_df = pd.DataFrame(rows)\n",
    "final_df.info()\n",
    "\n",
    "final_df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['vectorized', 'lemmatized_no_numbers', 'lemmatized'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\reosk\\projects\\text-categorizer\\src\\notebooks\\4_final_data_processing_glove.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/reosk/projects/text-categorizer/src/notebooks/4_final_data_processing_glove.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Concat\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/reosk/projects/text-categorizer/src/notebooks/4_final_data_processing_glove.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Remove unnecessary columns\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/reosk/projects/text-categorizer/src/notebooks/4_final_data_processing_glove.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m reduced_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(df\u001b[39m.\u001b[39;49mdrop(labels\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mvectorized\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlemmatized_no_numbers\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlemmatized\u001b[39;49m\u001b[39m'\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m'\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/reosk/projects/text-categorizer/src/notebooks/4_final_data_processing_glove.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m reduced_df\u001b[39m.\u001b[39mhead(\u001b[39m4\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/reosk/projects/text-categorizer/src/notebooks/4_final_data_processing_glove.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m merged_ds \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([final_df, reduced_df], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, join\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\reosk\\.virtualenvs\\text-categorizer-U9aCXgNA\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\reosk\\.virtualenvs\\text-categorizer-U9aCXgNA\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\reosk\\.virtualenvs\\text-categorizer-U9aCXgNA\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\reosk\\.virtualenvs\\text-categorizer-U9aCXgNA\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['vectorized', 'lemmatized_no_numbers', 'lemmatized'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Concat\n",
    "# Remove unnecessary columns\n",
    "\n",
    "reduced_df = pd.DataFrame(df.drop(labels=['vectorized', 'lemmatized_no_numbers', 'lemmatized'], axis='columns', inplace=False))\n",
    "reduced_df.head(4)\n",
    "\n",
    "merged_ds = pd.concat([final_df, reduced_df], axis=1, join='inner')\n",
    "merged_ds.info()\n",
    "merged_ds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ds.to_csv('../../output_data/4_2_vectorized_ds_glove_25.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
